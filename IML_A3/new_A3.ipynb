{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 13:44:06.925434: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pd_data(data):\n",
    "    label_data = data.iloc[:8000, :]\n",
    "    unlabel_data = data.iloc[8000:, :]\n",
    "\n",
    "    return label_data, unlabel_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_data = pd.read_csv('raw-data/train.csv')\n",
    "test_raw_data = pd.read_csv('raw-data/test.csv')\n",
    "val_raw_data = pd.read_csv('raw-data/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_id                    object\n",
       "requirements_and_role     object\n",
       "salary_bin               float64\n",
       "mean_salary              float64\n",
       "gender_code              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_raw_data, unlabel_raw_data = split_pd_data(train_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 5), (5902, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_raw_data.shape, unlabel_raw_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_np_data(data):\n",
    "    label_data = data[:8000, :]\n",
    "    unlabel_data = data[8000:, :]\n",
    "\n",
    "    return label_data, unlabel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_data = np.load('embeddings-data/train-embeddings.npy')\n",
    "val_emb_data = np.load('embeddings-data/valid-embeddings.npy')\n",
    "test_emb_data = np.load('embeddings-data/test-embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_emb_data, unlabel_emb_data = split_np_data(train_emb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 384), (5902, 384))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_emb_data.shape, unlabel_emb_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_data = np.load('tfidf-data/train-tfidf.npy')\n",
    "val_tfidf_data = np.load('tfidf-data/valid-tfidf.npy')\n",
    "test_tfidf_data = np.load('tfidf-data/test-tfidf.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tfidf_data, ublabel_tfidf_data = split_np_data(train_tfidf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13902, 500), (1737, 500), (1738, 500))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf_data.shape, val_tfidf_data.shape, test_tfidf_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeled data\n",
    "\n",
    "### Firstly, using Labeled Embedding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train = label_emb_data\n",
    "y_train = label_raw_data['salary_bin'].values\n",
    "X_val = val_emb_data\n",
    "y_val = val_raw_data['salary_bin'].values\n",
    "labels = np.unique(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondly, we test the tfidf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = label_tfidf_data\n",
    "# y_train = label_raw_data['salary_bin'].values\n",
    "# X_val = val_tfidf_data\n",
    "# y_val = val_raw_data['salary_bin'].values\n",
    "# labels = np.unique(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_knn(k, weights, p, X_train, y_train, X_test, y_test):\n",
    "    # Create a kNN classifier with the given parameters\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k, weights=weights, p=p)\n",
    "    \n",
    "    # Train the classifier\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy and other metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, report, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(1, 11))\n",
    "weights_options = ['uniform', 'distance']\n",
    "p_values = [1, 2]  # 1 = Manhattan distance, 2 = Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in k_values:\n",
    "#     for weights in weights_options:\n",
    "#         for p in p_values:\n",
    "#             with wandb.init(project=\"Assignment3-tfidf\", config={\"k\": k, \"weights\": weights, \"p\": p}, group=\"grid_search\") as run:\n",
    "#                 config = wandb.config\n",
    "                \n",
    "#                 # Train and evaluate the kNN classifier\n",
    "#                 accuracy, report, cm = train_and_evaluate_knn(config.k, config.weights, config.p, X_train, y_train, X_val, y_val)\n",
    "                \n",
    "#                 # Log the results to WandB\n",
    "#                 wandb.log({\"accuracy\": accuracy, \"classification_report\": report, \"confusion_matrix\": cm})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = KNeighborsClassifier(n_neighbors=3, weights='distance', p=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_dt(criterion, splitter, max_depth, min_samples_split, min_samples_leaf, X_train, y_train, X_test, y_test):\n",
    "    # Create a decision tree classifier with the given parameters\n",
    "    dt_clf = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "    \n",
    "    # Train the classifier\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy and other metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ['gini', 'entropy']\n",
    "splitter = ['best', 'random']\n",
    "max_depth = [5, 10, 15]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in criterion:\n",
    "#     for s in splitter:\n",
    "#         for d in max_depth:\n",
    "#             for ss in min_samples_split:\n",
    "#                 for sl in min_samples_leaf:\n",
    "#                     with wandb.init(project=\"Assignment3-tfidf\", config={\"criterion\": c, \"splitter\": s, \"max_depth\": d, \"min_samples_split\": ss, \"min_samples_leaf\": sl}, group=\"dt_grid_search\") as run:\n",
    "#                         config = wandb.config\n",
    "\n",
    "#                         # Train and evaluate the decision tree classifier\n",
    "#                         accuracy, report, cm = train_and_evaluate_dt(config.criterion, config.splitter, config.max_depth, config.min_samples_split, config.min_samples_leaf, X_train, y_train, X_val, y_val)\n",
    "\n",
    "#                         # Log the results to WandB\n",
    "#                         wandb.log({\"accuracy\": accuracy, \"classification_report\": report, \"confusion_matrix\": cm})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_GNB(var_smoothing, X_train, y_train, X_test, y_test):\n",
    "    # Create a Gaussian Naive Bayes classifier with the given parameters\n",
    "    gnb_clf = GaussianNB(var_smoothing=var_smoothing)\n",
    "    \n",
    "    # Train the classifier\n",
    "    gnb_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = gnb_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy and other metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_smoothing = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for v in var_smoothing:\n",
    "#     with wandb.init(project=\"Assignment3-tfidf\", config={\"var_smoothing\": v}, group=\"gnb_grid_search\") as run:\n",
    "#         config = wandb.config\n",
    "\n",
    "#         # Train and evaluate the Gaussian Naive Bayes classifier\n",
    "#         accuracy, report, cm = train_and_evaluate_GNB(config.var_smoothing, X_train, y_train, X_val, y_val)\n",
    "\n",
    "#         # Log the results to WandB\n",
    "#         wandb.log({\"accuracy\": accuracy, \"classification_report\": report, \"confusion_matrix\": cm})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BernoulliNB clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_BNB(alpha, binarize, X_train, y_train, X_test, y_test):\n",
    "    # Create a Bernoulli Naive Bayes classifier with the given parameters\n",
    "    bnb_clf = BernoulliNB(alpha=alpha, binarize=binarize)\n",
    "    \n",
    "    # Train the classifier\n",
    "    bnb_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = bnb_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy and other metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.1, 0.5, 1.0, 1.5, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a in alpha:\n",
    "#     with wandb.init(project=\"Assignment3-tfidf\", config={\"alpha\": a}, group=\"bnb_grid_search\") as run:\n",
    "#         config = wandb.config\n",
    "\n",
    "#         # Train and evaluate the Bernoulli Naive Bayes classifier\n",
    "#         accuracy, report, cm = train_and_evaluate_BNB(config.alpha, 0.0, X_train, y_train, X_val, y_val)\n",
    "\n",
    "#         # Log the results to WandB\n",
    "#         wandb.log({\"accuracy\": accuracy, \"classification_report\": report, \"confusion_matrix\": cm})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_adaboost(n_estimators, learning_rate, X_train, y_train, X_val, y_val):\n",
    "    clf = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    report = classification_report(y_val, y_pred)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    return accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 150, 200, 250]\n",
    "learning_rate = [0.1, 0.5, 1.0, 1.5, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in n_estimators:\n",
    "#     for l in learning_rate:\n",
    "#         with wandb.init(project=\"Assignment3-tfidf\", config={\"n_estimators\": n, \"learning_rate\": l}, group=\"adaboost_grid_search\") as run:\n",
    "#             config = wandb.config\n",
    "\n",
    "#             # Train and evaluate the Bernoulli Naive Bayes classifier\n",
    "#             accuracy, report, cm = train_and_evaluate_adaboost(config.n_estimators, config.learning_rate, X_train, y_train, X_val, y_val)\n",
    "\n",
    "#             # Log the results to WandB\n",
    "#             wandb.log({\"accuracy\": accuracy, \"classification_report\": report, \"confusion_matrix\": cm}) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost + Decision Tree clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_adaboost_with_model(base_estimator, n_estimators, learning_rate, X_train, y_train, X_val, y_val):\n",
    "    clf = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    report = classification_report(y_val, y_pred)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    return accuracy, report, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [1, 3, 5, 7, 9]\n",
    "n_estimators = [50, 100, 150]\n",
    "learning_rate = [0.1, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in max_depth:\n",
    "#     for n in n_estimators:\n",
    "#         for l in learning_rate:\n",
    "#             with wandb.init(project=\"Assignment3-tfidf\", config={\"max_depth\": d, \"n_estimators\": n, \"learning_rate\": l}, group=\"adaboost+dt_grid_search\") as run:\n",
    "#                 config = wandb.config\n",
    "\n",
    "#                 # Train and evaluate the Bernoulli Naive Bayes classifier\n",
    "#                 accuracy, report, cm = train_and_evaluate_adaboost_with_model(DecisionTreeClassifier(max_depth=config.max_depth), config.n_estimators, config.learning_rate, X_train, y_train, X_val, y_val)\n",
    "\n",
    "#                 # Log the results to WandB\n",
    "#                 wandb.log({\"accuracy\": accuracy, \"classification_report\": report, \"confusion_matrix\": cm})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNB + AdaBoost clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 150]\n",
    "learning_rate = [0.1, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in n_estimators:\n",
    "#     for l in learning_rate:\n",
    "#         with wandb.init(project=\"Assignment3-tfidf\", config={\"n_estimators\": n, \"learning_rate\": l}, group=\"adaboost+gnb_grid_search\") as run:\n",
    "#             config = wandb.config\n",
    "\n",
    "#             # Train and evaluate the Bernoulli Naive Bayes classifier\n",
    "#             accuracy, report, cm = train_and_evaluate_adaboost_with_model(GaussianNB(), config.n_estimators, config.learning_rate, X_train, y_train, X_val, y_val)\n",
    "\n",
    "#             # Log the results to WandB\n",
    "#             wandb.log({\"accuracy\": accuracy, \"classification_report\": report, \"confusion_matrix\": cm})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BNB + AdaBoost clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 150]\n",
    "learning_rate = [0.1, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in n_estimators:\n",
    "#     for l in learning_rate:\n",
    "#         with wandb.init(project=\"Assignment3-tfidf\", config={\"n_estimators\": n, \"learning_rate\": l}, group=\"adaboost+bnb_grid_search\") as run:\n",
    "#             config = wandb.config\n",
    "\n",
    "#             # Train and evaluate the Bernoulli Naive Bayes classifier\n",
    "#             accuracy, report, cm = train_and_evaluate_adaboost_with_model(BernoulliNB(), config.n_estimators, config.learning_rate, X_train, y_train, X_val, y_val)\n",
    "\n",
    "#             # Log the results to WandB\n",
    "#             wandb.log({\"accuracy\": accuracy, \"classification_report\": report, \"confusion_matrix\": cm})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_svm(kernel, C, X_train, y_train, X_val, y_val):\n",
    "    clf = SVC(kernel=kernel, C=C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    report = classification_report(y_val, y_pred)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    return accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C = [0.1, 0.5, 1.0, 1.5, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in kernel:\n",
    "#     for c in C:\n",
    "#         with wandb.init(project=\"Assignment3-emb\", config={\"kernel\": k, \"C\": c}, group=\"svm_grid_search\") as run:\n",
    "#             config = wandb.config\n",
    "\n",
    "#             # Train and evaluate the Bernoulli Naive Bayes classifier\n",
    "#             accuracy, report, cm = train_and_evaluate_svm(config.kernel, config.C, X_train, y_train, X_val, y_val)\n",
    "\n",
    "#             # Log the results to WandB\n",
    "#             wandb.log({\"accuracy\": accuracy, \"classification_report\": report, \"confusion_matrix\": cm})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly', C=2.0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(test_emb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw_data['salary_bin'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>requirements_and_role</th>\n",
       "      <th>gender_code</th>\n",
       "      <th>salary_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOB-2019-0016087</td>\n",
       "      <td>7am 1pm 1pm 7pm part time 5 day work week satu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOB-2019-0008055</td>\n",
       "      <td>legal counsel function corporate generalist pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JOB-2019-0001658</td>\n",
       "      <td>responsibilities manage various types engineer...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOB-2019-0016777</td>\n",
       "      <td>passionate technologists believe power softwar...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB-2019-0017600</td>\n",
       "      <td>looking process analyst permanent stable oppor...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_id                              requirements_and_role  \\\n",
       "0  JOB-2019-0016087  7am 1pm 1pm 7pm part time 5 day work week satu...   \n",
       "1  JOB-2019-0008055  legal counsel function corporate generalist pr...   \n",
       "2  JOB-2019-0001658  responsibilities manage various types engineer...   \n",
       "3  JOB-2019-0016777  passionate technologists believe power softwar...   \n",
       "4  JOB-2019-0017600  looking process analyst permanent stable oppor...   \n",
       "\n",
       "   gender_code  salary_bin  \n",
       "0            0           0  \n",
       "1            0           9  \n",
       "2            1           2  \n",
       "3            2           7  \n",
       "4            2           6  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get job_id and salary_bin to csv\n",
    "\n",
    "# test_raw_data[['job_id', 'salary_bin']].to_csv('test_salaries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
